{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "## **Local Chatbot with Postgres Integration**\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: justify;\">\n",
    "\n",
    "This project showcases a local chatbot implementation that uses a PostgreSQL database to store and retrieve chat conversation history. The diagram below illustrates the chatbot's high-level workflow.\n",
    "\n",
    "In this system, the user provides a prompt to the chatbot, which is then saved to its memory via the PostgreSQL database. LangChain retrieves both the user prompt and the stored memory from the database. These inputs are processed by the OpenAI chat model, which determines whether to generate a response based solely on the user prompt or by incorporating the stored memory. OpenAI is chosen due to harwdware's resource constraint on running opensource LLMs. Finally, the model's output becomes the chatbot's response, which is also saved back into the database.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <figure>\n",
    "        <img src=\"images/block_diagram.png\" alt=\"Alt text\" width=\"1000\"/>\n",
    "        <figcaption style=\"margin-top: 10px; font-style: Normal;\">\n",
    "            Figure 1: High-level workflow of the local chatbot.\n",
    "        </figcaption>\n",
    "    </figure>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up PostgreSQL Database with Chat History Table\n",
    "\n",
    "To set up the PostgreSQL database for storing chat history, follow the steps below. This setup uses a `Dockerfile`, `docker-compose.yaml`, and an `init.sql` script to automate the database initialization.\n",
    "\n",
    "#### Dockerfile\n",
    "```dockerfile\n",
    "FROM postgres:latest\n",
    "\n",
    "COPY init.sql /docker-entrypoint-initdb.d/\n",
    "\n",
    "EXPOSE 5432\n",
    "```\n",
    "\n",
    "- **Base Image**: Uses the latest official PostgreSQL image.\n",
    "- **Initialization Script**: The `init.sql` file is copied into the container's initialization directory. PostgreSQL automatically runs this script during the container startup.\n",
    "- **Port Exposure**: Exposes port `5432` for database connections.\n",
    "\n",
    "#### docker-compose.yaml\n",
    "```yaml\n",
    "services:\n",
    "  postgres:\n",
    "    build:\n",
    "      context: .\n",
    "    container_name: chatbot_postgres\n",
    "    ports:\n",
    "      - \"5432:5432\"\n",
    "    volumes:\n",
    "      - /var/lib/postgresql/data\n",
    "    environment:\n",
    "      POSTGRES_USER: ${POSTGRES_USER}\n",
    "      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}\n",
    "      POSTGRES_DB: ${POSTGRES_DB}\n",
    "    env_file:\n",
    "      - .env\n",
    "```\n",
    "\n",
    "- **Build Context**: Builds the PostgreSQL image using the `Dockerfile` in the current directory.\n",
    "- **Container Name**: Names the container `chatbot_postgres` for easier identification.\n",
    "- **Ports**: Maps port `5432` of the container to the host machine.\n",
    "- **Volumes**: Temporary persists PostgreSQL data in `/var/lib/postgresql/data`.\n",
    "- **Environment Variables**: Reads database credentials from the `.env` file for secure configuration.\n",
    "\n",
    "#### init.sql\n",
    "```sql\n",
    "CREATE TABLE IF NOT EXISTS chat_history (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    session_id UUID NOT NULL,\n",
    "    role TEXT NOT NULL,\n",
    "    content TEXT NOT NULL,\n",
    "    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "```\n",
    "\n",
    "**Table Creation**: Defines the `chat_history` table with the following columns:\n",
    "  - `id`: A unique identifier for each entry.\n",
    "  - `session_id`: A UUID to group messages by session.\n",
    "  - `role`: Specifies whether the message is from the user or the assistant.\n",
    "  - `content`: The message text.\n",
    "  - `timestamp`: Automatically records the time of entry.\n",
    "\n",
    "After setting up the three files, database can be created by running `docker-compose up --build` command in any device's terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Implementation\n",
    "\n",
    "Assuming that `requirements.txt` is already installed, we can now import the necessary packages. I will be discussing later the importance of each packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import uuid\n",
    "import os\n",
    "import psycopg\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_postgres import PostgresChatMessageHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and initialize the model\n",
    "\n",
    "Here, `gpt-3.5-turbo` was used since it is good in conversational tasks and is cost-effective compared to GPT-4 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OpenAI API Key\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatOpenAI(model = \"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the prompt template\n",
    "\n",
    "The next code initializes a prompt template for a conversational AI model, where a user’s question is inserted into the human_template. The `MessagesPlaceholder(variable_name=\"history\")` creates a placeholder for including chat history in the prompt. This allows the model to incorporate past messages for generating contextually relevant responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = f\"{{question}}\"\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", human_template),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chain the prompt and model. Define table name\n",
    "\n",
    "Here, the code chains the prompt template with the model This creates a pipeline where the model generates responses based on the structured input. It also defines the table name `chat_history` for storing chat history in a Postgres database. The chat history will be stored and retrieved from this table for each user session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain the prompt and model\n",
    "chain = prompt_template | model\n",
    "\n",
    "# Define table name for PostgreSQL\n",
    "table_name = \"chat_history\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to retrieve chat history\n",
    "\n",
    "This code defines a function `get_by_session_id` that retrieves chat history from a PostgreSQL database based on a given session ID. The function returns a PostgresChatMessageHistory object, which loads the chat history for the specified session from the `chat_history` table.\n",
    "\n",
    "`BaseChatMessageHistory` is an abstract class that provides a common interface for managing chat message history across different storage systems. In this code, `PostgresChatMessageHistory` inherits from it which offers a Postgres-specific implementation to retrieve and manage chat history for a given session ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_by_session_id(session_id: str) -> BaseChatMessageHistory:\n",
    "    sync_connection = psycopg.connect(\n",
    "        dbname=os.getenv(\"POSTGRES_DB\"),\n",
    "        user=os.getenv(\"POSTGRES_USER\"),\n",
    "        password=os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\",\n",
    "    )\n",
    "    return PostgresChatMessageHistory(\n",
    "        table_name, session_id, sync_connection=sync_connection\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chain the prompt, model, and history retriever\n",
    "\n",
    "The next code enables the model to generate responses considering both the current question, and the conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_by_session_id,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to delete chat history\n",
    "\n",
    "This code defines a function `delete_chat_history` that removes chat history from a PostgreSQL database for a given session ID. It establishes a connection to the database, executes a `DELETE` SQL query to remove the records from the `chat_history` table, and commits the changes.\n",
    "\n",
    "This function will be used whenever the user intends to create a new chat conversation with the chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_chat_history(session_id: str):\n",
    "    with psycopg.connect(\n",
    "        dbname=os.getenv(\"POSTGRES_DB\"),\n",
    "        user=os.getenv(\"POSTGRES_USER\"),\n",
    "        password=os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\",\n",
    "    ) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\n",
    "                f\"DELETE FROM {table_name} WHERE session_id = %s\", (session_id,)\n",
    "            )\n",
    "            conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Streamlit session variables\n",
    "\n",
    "Here, the code make sure that a new, unique session ID through `uuid` library will be created whenever no session ID exists. It also initializes the `chat_history` as an empty list if it does not exist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 20:05:07.599 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-08 20:05:07.602 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-08 20:05:07.603 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-08 20:05:07.603 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-08 20:05:07.603 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-08 20:05:07.603 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "if \"session_id\" not in st.session_state:\n",
    "    st.session_state.session_id = str(uuid.uuid4())  # Generate unique session ID for a user\n",
    "\n",
    "if \"chat_history\" not in st.session_state:\n",
    "    st.session_state.chat_history = []  # Initialize chat history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streamlit User Interface\n",
    "\n",
    "The code will mimic how the chatbot works. It will display first the title `Local Chatbot using ChatOpenAI`, then the conversations will be also displayed in the interface. A streamlit's  chat_input` was also set to let the users type their queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 20:05:50.798 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-08 20:05:50.803 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-08 20:05:50.804 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-08 20:05:50.805 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-08 20:05:50.807 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-08 20:05:50.810 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-08 20:05:50.813 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-08 20:05:50.816 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Title of the website\n",
    "st.title(\"Local Chatbot using ChatOpenAI\")\n",
    "\n",
    "# Display chat history\n",
    "for message in st.session_state.chat_history:\n",
    "    if message[\"role\"] == \"user\":\n",
    "        st.chat_message(\"user\").markdown(message[\"content\"])\n",
    "    else:\n",
    "        st.chat_message(\"assistant\").markdown(message[\"content\"])\n",
    "\n",
    "# Request user to input prompt\n",
    "user_question = st.chat_input(\"Message Me: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Conversation Workflow\n",
    "\n",
    "When the user submits a question, it is displayed in the chat, and the model's response is generated using `chain_with_history`, which considers the chat history for context. The response from the model is then shown in the chat, and both the user’s question and the assistant’s response are saved to the chat_history for the current session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User submits the question\n",
    "if user_question:\n",
    "    # Show user message in the chat\n",
    "    st.chat_message(\"user\").markdown(user_question)\n",
    "\n",
    "    # Get the chatbot's response\n",
    "    result = chain_with_history.invoke(\n",
    "        {\"question\": user_question},\n",
    "        config={\"configurable\": {\"session_id\": st.session_state.session_id}},\n",
    "    )\n",
    "    \n",
    "    # Show chatbot's response in the chat\n",
    "    st.chat_message(\"assistant\").markdown(result.content)\n",
    "    \n",
    "    # Save the conversation in chat history\n",
    "    st.session_state.chat_history.append({\"role\": \"user\", \"content\": user_question})\n",
    "    st.session_state.chat_history.append({\"role\": \"assistant\", \"content\": result.content})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For New Conversation\n",
    "\n",
    "This deletes the current chat history from the Postgres database, generates a new unique session ID, and clears the chat_history in the session state. After these changes, it reruns the Streamlit app which resets the chat interface for the new conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 20:09:48.291 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-08 20:09:48.292 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-08 20:09:48.293 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-08 20:09:48.293 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-08 20:09:48.293 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# When new conversation is initiated\n",
    "if st.button(\"Start New Conversation\"):\n",
    "    # Delete chat history from the PostgreSQL database\n",
    "    delete_chat_history(st.session_state.session_id)\n",
    "    \n",
    "    # Generate a new session ID\n",
    "    st.session_state.session_id = str(uuid.uuid4())\n",
    "    \n",
    "    # Clear chat history in website's session state\n",
    "    st.session_state.chat_history = []\n",
    "    \n",
    "    # Rerun the app\n",
    "    st.rerun()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### END\n",
    "\n",
    "This is the end. Since this is a Jupyter Notebook, I cannot directly run the code. However, you can look at the link below for the video demo of the created chatbot.\n",
    "\n",
    "**Demo**: https://drive.google.com/file/d/1PaKOBu-HsbcBWVB8cfexGPsqWhKz9t4c/view?usp=sharing\n",
    "\n",
    "\n",
    "**Additional Note**\n",
    "- You can run the code using `streamlit run app.py` command. The file `app.py` contains the same code here in the documentation.\n",
    "- GitHub Repository: https://github.com/Rob-Christian/My-Local-Chatbot\n",
    "- I did not use opensource LLM and Llama-Cpp-Python due to hardware resource constraint. A single prompt inference of the chatbot takes more than a minute for 4-bit quantized version of Llama-7b. The inference time is also increasing as the conversation continues due to added memory input to the model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bluedrive_solutions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
